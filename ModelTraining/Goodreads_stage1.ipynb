{"cells":[{"cell_type":"markdown","metadata":{"id":"Gp5L_VXbtxAi"},"source":["# Installs, Imports, Drive Connection, WandB Connection"]},{"cell_type":"markdown","metadata":{"id":"fTDqhCRUt3HT"},"source":["##### Installs"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66743,"status":"ok","timestamp":1628971311095,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"MYJcwbartY2A","outputId":"81bfcca7-3262-4657-8b82-c7820272c16c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-7wt9f7t3\n","  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-7wt9f7t3\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2.23.0)\n","Collecting tokenizers\u003c0.11,\u003e=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (21.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.6.3)\n","Collecting huggingface-hub\u003e=0.0.12\n","  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 950 kB/s \n","\u001b[?25hCollecting pyyaml\u003e=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 36.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (4.62.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0.dev0) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003e=0.0.12-\u003etransformers==4.10.0.dev0) (3.7.4.3)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etransformers==4.10.0.dev0) (2.4.7)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.10.0.dev0) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0.dev0) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0.dev0) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0.dev0) (2021.5.30)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.10.0.dev0) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0.dev0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0.dev0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.10.0.dev0) (1.15.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.10.0.dev0-py3-none-any.whl size=2644547 sha256=5aa2f9c9fdb30597722d82fff161dd73ab9a41d2fa9c6ef0e9278ee140f9fd94\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-c5nzkrkr/wheels/90/a5/44/6bcd83827c8a60628c5ad602f429cd5076bcce5f2a90054947\n","Successfully built transformers\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.15 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0.dev0\n","Collecting datasets==1.9.0\n","  Downloading datasets-1.9.0-py3-none-any.whl (262 kB)\n","\u001b[K     |████████████████████████████████| 262 kB 4.1 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 47.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (1.1.5)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (2.23.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (4.62.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (0.70.12.2)\n","Requirement already satisfied: huggingface-hub\u003c0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (0.0.15)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (4.6.3)\n","Collecting fsspec\u003e=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 54.3 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (0.3.4)\n","Requirement already satisfied: pyarrow!=4.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (3.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (21.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.9.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c0.1.0-\u003edatasets==1.9.0) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c0.1.0-\u003edatasets==1.9.0) (3.0.12)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003edatasets==1.9.0) (2.4.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets==1.9.0) (2021.5.30)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets==1.9.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets==1.9.0) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets==1.9.0) (2.10)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003edatasets==1.9.0) (3.5.0)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets==1.9.0) (2018.9)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets==1.9.0) (2.8.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas-\u003edatasets==1.9.0) (1.15.0)\n","Installing collected packages: xxhash, fsspec, datasets\n","Successfully installed datasets-1.9.0 fsspec-2021.7.0 xxhash-2.0.2\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (5.4.1)\n","Collecting ray[default]\n","  Downloading ray-1.5.2-cp37-cp37m-manylinux2014_x86_64.whl (51.0 MB)\n","\u001b[K     |████████████████████████████████| 51.0 MB 58 kB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.0.12)\n","Requirement already satisfied: numpy\u003e=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.19.5)\n","Requirement already satisfied: click\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (7.1.2)\n","Requirement already satisfied: prometheus-client\u003e=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.11.0)\n","Collecting aiohttp-cors\n","  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n","Collecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 41.0 MB/s \n","\u001b[?25hCollecting gpustat\n","  Downloading gpustat-0.6.0.tar.gz (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 6.6 MB/s \n","\u001b[?25hCollecting pydantic\u003e=1.8\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 46.5 MB/s \n","\u001b[?25hRequirement already satisfied: msgpack\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]) (2.23.0)\n","Requirement already satisfied: protobuf\u003e=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.17.3)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting aioredis\u003c2\n","  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 3.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]) (5.4.1)\n","Collecting redis\u003e=3.5.0\n","  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 566 kB/s \n","\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]) (2.6.0)\n","Requirement already satisfied: grpcio\u003e=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.34.1)\n","Collecting py-spy\u003e=0.2.0\n","  Downloading py_spy-0.3.8-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 32.9 MB/s \n","\u001b[?25hCollecting opencensus\n","  Downloading opencensus-0.7.13-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 55.3 MB/s \n","\u001b[?25hCollecting colorful\n","  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n","\u001b[K     |████████████████████████████████| 201 kB 44.2 MB/s \n","\u001b[?25hCollecting hiredis\n","  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 4.3 MB/s \n","\u001b[?25hCollecting async-timeout\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: six\u003e=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio\u003e=1.28.1-\u003eray[default]) (1.15.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic\u003e=1.8-\u003eray[default]) (3.7.4.3)\n","Collecting yarl\u003c2.0,\u003e=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 44.0 MB/s \n","\u001b[?25hRequirement already satisfied: chardet\u003c5.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003eray[default]) (3.0.4)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003eray[default]) (21.2.0)\n","Collecting multidict\u003c7.0,\u003e=4.5\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 52.1 MB/s \n","\u001b[?25hRequirement already satisfied: idna\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl\u003c2.0,\u003e=1.0-\u003eaiohttp-\u003eray[default]) (2.10)\n","Requirement already satisfied: nvidia-ml-py3\u003e=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat-\u003eray[default]) (7.352.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat-\u003eray[default]) (5.4.8)\n","Collecting blessings\u003e=1.6\n","  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n","Requirement already satisfied: google-api-core\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus-\u003eray[default]) (1.26.3)\n","Collecting opencensus-context==0.1.2\n","  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n","Requirement already satisfied: setuptools\u003e=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (57.2.0)\n","Requirement already satisfied: packaging\u003e=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (21.0)\n","Requirement already satisfied: googleapis-common-protos\u003c2.0dev,\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (1.53.0)\n","Requirement already satisfied: google-auth\u003c2.0dev,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (1.34.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (2018.9)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2.0dev,\u003e=1.21.1-\u003egoogle-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (4.7.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2.0dev,\u003e=1.21.1-\u003egoogle-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (0.2.8)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2.0dev,\u003e=1.21.1-\u003egoogle-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (4.2.2)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=14.3-\u003egoogle-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (2.4.7)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c2.0dev,\u003e=1.21.1-\u003egoogle-api-core\u003c2.0.0,\u003e=1.0.0-\u003eopencensus-\u003eray[default]) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eray[default]) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eray[default]) (2021.5.30)\n","Building wheels for collected packages: gpustat\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=0d07cac929d768767a1943dd9c1fe2ce6fbe7239289ebb7943bbc9efe42bb1bd\n","  Stored in directory: /root/.cache/pip/wheels/e6/67/af/f1ad15974b8fd95f59a63dbf854483ebe5c7a46a93930798b8\n","Successfully built gpustat\n","Installing collected packages: multidict, yarl, async-timeout, opencensus-context, hiredis, blessings, aiohttp, redis, pydantic, py-spy, opencensus, gpustat, colorama, aioredis, aiohttp-cors, ray, colorful\n","Successfully installed aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 gpustat-0.6.0 hiredis-2.0.0 multidict-5.1.0 opencensus-0.7.13 opencensus-context-0.1.2 py-spy-0.3.8 pydantic-1.8.2 ray-1.5.2 redis-3.5.3 yarl-1.6.3\n","Collecting wandb\n","  Downloading wandb-0.12.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.2 MB/s \n","\u001b[?25hCollecting subprocess32\u003e=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s \n","\u001b[?25hCollecting GitPython\u003e=1.0.0\n","  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil\u003e=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting configparser\u003e=3.8.1\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting sentry-sdk\u003e=1.0.0\n","  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 52.9 MB/s \n","\u001b[?25hCollecting docker-pycreds\u003e=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: protobuf\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting shortuuid\u003e=0.5.0\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (3.7.4.3)\n","Collecting gitdb\u003c5,\u003e=4.0.1\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hCollecting smmap\u003c5,\u003e=3.0.1\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2021.5.30)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=03997469ccfe3001cdc697bb87314e99440b677d55814998e7c67b7f1dace9f5\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=d304f7820a9f90bc69ca6f964780720bfc461610847a1977a322b16f7741baf4\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.12.0\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n","\u001b[K     |████████████████████████████████| 124 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf\u003e=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf\u003e=3.8.0-\u003etensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.4\n"]}],"source":["# !pip install transformers\n","!pip install git+https://github.com/huggingface/transformers.git\n","!pip install datasets==1.9.0\n","!pip install -U PyYAML\n","!pip install \"ray[default]\"\n","!pip install wandb\n","!pip install tensorboardX"]},{"cell_type":"markdown","metadata":{"id":"rCsyqPset6dy"},"source":["##### Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5649,"status":"ok","timestamp":1628971640187,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"CqYDmipPt5vR"},"outputs":[],"source":["import sys\n","import os\n","import numpy as np\n","# from transformers import pipeline\n","from datasets import concatenate_datasets, load_dataset\n","import torch\n","from pathlib import Path\n","import pickle\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from transformers import Trainer, TrainingArguments\n","from scipy.special import softmax\n","from sklearn.metrics import f1_score, precision_recall_curve, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import math\n","from transformers import AutoModelForSequenceClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wQn6xfRzRhH"},"outputs":[],"source":["import os\n","import pickle\n","import numpy as np\n","\n","import ray\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import PopulationBasedTraining, ASHAScheduler\n","from transformers import Trainer, TrainingArguments\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from ray.tune.logger import DEFAULT_LOGGERS\n","from ray.tune.integration.wandb import WandbLoggerCallback, WandbLogger\n","\n","from transformers import DistilBertConfig\n","\n","from ray.tune.integration.wandb import WandbLoggerCallback\n","# from MultiTaskExtensions import DistilBERTForMultipleSequenceClassification"]},{"cell_type":"markdown","metadata":{"id":"UlNbZBmyt_FS"},"source":["##### Drive Connection"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1628971645357,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"9jEJvuPit9vd","outputId":"909f5686-f4e1-4f9c-c6eb-982ab3a0d73f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"hUtmDSYEfQ0M"},"source":["##### Get Configuration"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2315,"status":"ok","timestamp":1628971651199,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"zMYGmKuqfTK5"},"outputs":[],"source":["import configparser\n","import sys\n","from pathlib import Path\n","\n","config = configparser.ConfigParser()\n","config.read('/content/drive/MyDrive/Thesis/BookSuccessPredictor/config.ini')\n","\n","drive_base_path = Path(config['Drive']['drive_base_path'])\n","\n","sys.path.append(str(drive_base_path / 'BookSuccessPredictor' / '_utils'))"]},{"cell_type":"markdown","metadata":{"id":"Ftr_j828j4Sc"},"source":["##### WandB Connection"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495,"status":"ok","timestamp":1628971652640,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"TK_BtgJrj8-F","outputId":"a720e64d-5e53-4ebe-84de-507bd167ba8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_LOG_MODEL=true\n","env: WANDB_PROJECT=goodreads_success_predictor\n"]}],"source":["# saves our models to artifacts in WandB\n","import wandb\n","%env WANDB_LOG_MODEL=true\n","%env WANDB_PROJECT=goodreads_success_predictor"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5964,"status":"ok","timestamp":1628971660223,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"UDrXDpMIbyct"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W\u0026B API key is configured (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login(key = config['WandB']['api_key'])"]},{"cell_type":"markdown","metadata":{"id":"lyW-LH6nvHBY"},"source":["# Dataset Generator"]},{"cell_type":"markdown","metadata":{"id":"saQOgEd7hjWf"},"source":["### Load Text Data"]},{"cell_type":"markdown","metadata":{"id":"Z-L4TuE8g8VC"},"source":["#### goodreads_maharjan"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":464653,"status":"ok","timestamp":1628897574129,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"_GU2ZkecvIlY","outputId":"62981972-40b7-48aa-9209-20cdbd6c0d0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset good_reads_practice_dataset/main_domain (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/good_reads_practice_dataset/main_domain/1.1.0/fee2eb60ac7713af6f776b7c4dab63145144f749e5689ea3dc2299235f6f560e...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e0177235a7446b2a13d4fc289d08f59","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"140cde2565c849bda260095566527cf8","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64b2150d960d4bfc81f5021602ee8fb8","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset good_reads_practice_dataset downloaded and prepared to /root/.cache/huggingface/datasets/good_reads_practice_dataset/main_domain/1.1.0/fee2eb60ac7713af6f776b7c4dab63145144f749e5689ea3dc2299235f6f560e. Subsequent calls will reuse this data.\n"]}],"source":["base_path = Path(config['Datasets']['nered_goodreads_maharjan_path'])\n","dataset = load_dataset(str(base_path / 'goodreadsnered.py'))"]},{"cell_type":"markdown","metadata":{"id":"G0yvGFjMhAbX"},"source":["#### goodreads_guarro"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"i_kWFv5jhCpV","outputId":"2717af71-e3b2-4942-e041-a3cc8eea6163"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset good_reads_practice_dataset/main_domain (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/good_reads_practice_dataset/main_domain/1.1.0/999b4ca5809d3ad7661b55bd6e5ac9572e0b279ffe251568f03012099946052d...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c09d521596c4af3a2bd9bb37a54923a","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["base_path = config['Datasets']['nered_goodreads_guarro_path']\n","dataset = load_dataset(base_path)"]},{"cell_type":"markdown","metadata":{"id":"OVtdWBx0h09i"},"source":["### Custom Tokenization Process"]},{"cell_type":"markdown","metadata":{"id":"xAAeka1DNAV9"},"source":["##### Get Tokenizer"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1628971686125,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"cUZHpyH4JScW"},"outputs":[],"source":["from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owH2-U4-JYzw","outputId":"87a696c0-9d1e-4563-e50f-337e98131fac"},"outputs":[{"name":"stdout","output_type":"stream","text":["adding special token for [CHARACTER]\n"]}],"source":["if eval(config['Model']['use_ner']):\n","  print(\"adding special token for [CHARACTER]\")\n","  tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-base', additional_special_tokens = ['[CHARACTER]'])\n","  # tokenizer = AutoTokenizer.from_pretrained(config['Model']['name'], additional_special_tokens = ['[CHARACTER]'])\n","else:\n","  tokenizer = AutoTokenizer.from_pretrained(config['Model']['name'])"]},{"cell_type":"markdown","metadata":{"id":"y2k2gNmd0V5k"},"source":["##### Do actual tokenizing and uploading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfqceoNYm9Xa"},"outputs":[],"source":["from tokenization_algos import chunk_and_encode_examples_w_complete_sentences, chunk_and_encode_examples_w_overlap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfGdetaTjWtp"},"outputs":[],"source":["from functools import partial\n","encode_algo = partial(chunk_and_encode_examples_w_overlap, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150},"executionInfo":{"elapsed":64060,"status":"ok","timestamp":1628897913165,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"3tfRMxPspRIT","outputId":"14e05124-26c3-4c6f-f649-a49f8e36c34b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac6af21188bf423f850eadf5b109dec9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?ba/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66af5a8512bd451fa9af725f57dc1caa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?ba/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6265ba8b14eb4d77979475f27b20ed49","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00\u003c?, ?ba/s]"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["chunked_encoded_dataset = dataset.map(encode_algo, remove_columns=dataset.column_names['train'], batched = True)"]},{"cell_type":"markdown","metadata":{"id":"xmq3ttP2xdtR"},"source":["When uploading the tokenized datasets to Drive, we may need to break them up into as many pieces as is necessary. Otherwise the serialization and uploading fails. In my case I had to split each subset (train, val, test) into 2 parts. If using tokenization with complete sentences, we can usually avoid this hack. Otherwise with overlap, the dataset will most likely be too large and this trick may be necessary."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1628897919739,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"5GkA1_OPm_uH","outputId":"81e133ed-94f1-489e-d684-fb24a1f2eb76"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'success_label', 'token_type_ids'],\n","        num_rows: 22639\n","    })\n","    validation: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'success_label', 'token_type_ids'],\n","        num_rows: 5482\n","    })\n","    test: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'success_label', 'token_type_ids'],\n","        num_rows: 11278\n","    })\n","})"]},"execution_count":16,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["chunked_encoded_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfIFipREwjkZ"},"outputs":[],"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)  \n","\n","with open('train_dataset1.pkl', 'wb') as output_file:\n","  pickle.dump(chunked_encoded_dataset['train'][0:chunked_encoded_dataset['train'].num_rows//2], output_file)\n","\n","with open('train_dataset2.pkl', 'wb') as output_file:\n","  pickle.dump(chunked_encoded_dataset['train'][chunked_encoded_dataset['train'].num_rows//2:chunked_encoded_dataset['train'].num_rows], output_file)\n","\n","with open('val_dataset1.pkl', 'wb') as output_file:\n","  pickle.dump(chunked_encoded_dataset['validation'][0:chunked_encoded_dataset['validation'].num_rows//2], output_file)\n","\n","with open('val_dataset2.pkl', 'wb') as output_file:\n","  pickle.dump(chunked_encoded_dataset['validation'][chunked_encoded_dataset['validation'].num_rows//2:chunked_encoded_dataset['validation'].num_rows], output_file)\n","\n","with open('test_dataset1.pkl', 'wb') as output_file:\n","  pickle.dump(chunked_encoded_dataset['test'][0:chunked_encoded_dataset['test'].num_rows//2], output_file)\n","\n","with open('test_dataset2.pkl', 'wb') as output_file:\n","  pickle.dump(chunked_encoded_dataset['test'][chunked_encoded_dataset['test'].num_rows//2:chunked_encoded_dataset['test'].num_rows], output_file)\n","\n","folder_id = '1uV1YCVJSX6RE6ZRdGBMpPts5edtPkfOp'\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n","file.SetContentFile('train_dataset1.pkl')\n","file.Upload() \n","\n","file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n","file.SetContentFile('train_dataset2.pkl')\n","file.Upload() \n","\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n","file.SetContentFile('val_dataset1.pkl')\n","file.Upload() \n","\n","file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n","file.SetContentFile('val_dataset2.pkl')\n","file.Upload() \n","\n","# get the folder id where you want to save your file\n","file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n","file.SetContentFile('test_dataset1.pkl')\n","file.Upload() \n","\n","file = drive.CreateFile({'parents':[{u'id': folder_id}]})\n","file.SetContentFile('test_dataset2.pkl')\n","file.Upload()"]},{"cell_type":"markdown","metadata":{"id":"uBZgml9JiIil"},"source":["#### Loading"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1628971710682,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"-I2ys-gbOvXn"},"outputs":[],"source":["load_path = Path(config['Drive']['drive_base_path']) / 'BookSuccessPredictor' / 'datasets' / 'goodreads_maharjan_super' / 'already_tokenized'"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1628971711770,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"IyHsdlQBD-vE"},"outputs":[],"source":["if config['Datasets']['split'] == '80_20':\n","  load_path = load_path / '80_20'\n","else:\n","  load_path = load_path / '60_40'"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":426,"status":"ok","timestamp":1628971714243,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"6ehOdQnyPiq5"},"outputs":[],"source":["if (config['Model']['name'] == 'albert-base-v2'):\n","  load_path = load_path / 'ALBERT_NER_512'\n","\n","elif (config['Model']['name'] == 'bert-base-uncased'):\n","  if (config['Tokenizer']['max_len'] == '512'):\n","    load_path = load_path / 'BERT_UNCASED_NER_512'\n","  elif (config['Tokenizer']['max_len'] == '256'):\n","    load_path = load_path / 'BERT_UNCASED_NER_256'\n","\n","elif (config['Model']['name'] == 'distilbert-base-uncased'):\n","  if (eval(config['Tokenizer']['overlap'])):\n","    load_path = load_path / 'DistilBERT_UNCASED_NER_512_w50overlap'\n","  else:\n","    load_path = load_path / 'DistilBERT_UNCASED_NER_512'\n","\n","elif (config['Model']['name'] == 'microsoft/deberta-base'):\n","  load_path = load_path / 'DeBERTa'\n","\n","elif (config['Model']['name'] == 'roberta-base'):\n","  load_path = load_path / 'ROBERTA_NER_512'\n","\n","elif (config['Model']['name'] == 'google/bigbird-roberta-base'):\n","  load_path = load_path / 'BIGBIRD_NER_4096'"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1628971715684,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"nppRfvDyZGof","outputId":"fd04a06b-5ead-402f-c516-a230cbf81419"},"outputs":[{"data":{"text/plain":["PosixPath('/content/drive/MyDrive/Thesis/BookSuccessPredictor/datasets/goodreads_maharjan_super/already_tokenized/80_20/DeBERTa')"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["load_path"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":23496,"status":"ok","timestamp":1628971741959,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"oHXEWzPkUHo-"},"outputs":[],"source":["from datasets import DatasetDict, Dataset, concatenate_datasets\n","train_paths = [f for f in os.listdir(load_path) if f.startswith('train')]\n","val_paths = [f for f in os.listdir(load_path) if f.startswith('val')]\n","test_paths = [f for f in os.listdir(load_path) if f.startswith('test')]\n","\n","train_datasets = []\n","val_datasets = []\n","test_datasets = []\n","\n","for trainp in train_paths:\n","  with open(load_path / trainp, \"rb\") as input_file:\n","    train_datasets.append(Dataset.from_dict(pickle.load(input_file)))\n","\n","for valp in val_paths:\n","  with open(load_path / valp, \"rb\") as input_file:\n","    val_datasets.append(Dataset.from_dict(pickle.load(input_file)))\n","\n","for testp in test_paths:\n","  with open(load_path / testp, \"rb\") as input_file:\n","    test_datasets.append(Dataset.from_dict(pickle.load(input_file)))\n","\n","train_dataset = concatenate_datasets(train_datasets)\n","del train_datasets\n","\n","val_dataset = concatenate_datasets(val_datasets)\n","del val_datasets\n","\n","test_dataset = concatenate_datasets(test_datasets)\n","del test_datasets\n","\n","chunked_encoded_dataset = DatasetDict({'train': train_dataset, 'validation': val_dataset, 'test': test_dataset})"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1628971744652,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"5mcFeMQgLEOP","outputId":"7bf8ceff-c82c-4db4-c088-536fceb13456"},"outputs":[{"name":"stdout","output_type":"stream","text":["single task\n"]}],"source":["if (eval(config['Model']['multi_task'])):\n","  print('multitask')\n","  # When batched = True, we take in multiple examples\n","  def group_success_and_genre(examples):\n","    examples['labels'] = np.vstack((examples['success_label'], examples['genre'])).T\n","    return examples\n","\n","  chunked_encoded_dataset = chunked_encoded_dataset.map(group_success_and_genre, batched = True, remove_columns=['genre', 'success_label'])\n","else:\n","  print('single task')\n","  chunked_encoded_dataset = chunked_encoded_dataset.rename_column('success_label', 'labels')"]},{"cell_type":"markdown","metadata":{"id":"xNtzoZdGJKF7"},"source":["#Dataset Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"m35LUkPSJmNS","outputId":"38f99e44-6dbf-4bb3-978b-2174ccdf9595"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'success_label', 'token_type_ids'],\n","        num_rows: 21539\n","    })\n","    validation: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'success_label', 'token_type_ids'],\n","        num_rows: 5236\n","    })\n","    test: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'success_label', 'token_type_ids'],\n","        num_rows: 10816\n","    })\n","})"]},"execution_count":0,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["chunked_encoded_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1626742436476,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"XlDjDuXSORXo","outputId":"3293b6b2-608c-4481-f59e-7c6fd3ebe68d"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import itertools\n","\n","num_segments_per_book = [len(list(g[1])) for g in itertools.groupby(chunked_encoded_dataset['train']['book_title'])]\n","\n","plt.hist(num_segments_per_book, density=True, bins=30)  # density=False would make counts\n","plt.ylabel('Probability')\n","plt.xlabel('Data');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1TsnXeKJqzz"},"outputs":[],"source":["# [(g[0], len(list(g[1]))) for g in itertools.groupby(chunked_encoded_dataset['train']['book_title'])]\n","start_of_segmented_book = {}\n","last_idx = 0\n","for g in itertools.groupby(chunked_encoded_dataset['train']['book_title']):\n","  start_of_segmented_book[g[0]] = last_idx\n","  last_idx = len(list(g[1])) + last_idx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1623116101618,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"DMvjgz4qNAo9","outputId":"32f21cab-744c-410f-85f9-3c863972c48f"},"outputs":[{"data":{"text/plain":["{'10002_the+house+on+the+borderland.txt': 10969,\n"," \"1006_divine+comedy+cary's+translation+purgatory.txt\": 8310,\n"," '10083_the+house+of+the+whispering+pines.txt': 12906,\n"," '1020_sword+blades+and+poppy+seed.txt': 6111,\n"," '10671_the+botanic+garden.txt': 9771,\n"," '1069_four+short+stories+by+emile+zola.txt': 391,\n"," '1074_the+sea+wolf.txt': 13453,\n"," '1093_the+beast+in+the+jungle.txt': 5285,\n"," '1096_the+faith+of+men.txt': 2218,\n"," \"1097_mrs+warren's+profession.txt\": 10188,\n"," '1144_in+the+cage.txt': 1945,\n"," '1151_the+nibelungenlied.txt': 9470,\n"," '11656_the+great+shadow+and+other+napoleonic+tales.txt': 10655,\n"," '12116_struwwelpeter+merry+stories+and+funny+pictures.txt': 8761,\n"," '1218_the+adventures+of+jimmie+dale.txt': 9606,\n"," '12241_poems+by+emily+dickinson+third+series.txt': 1754,\n"," '12242_poems+by+emily+dickinson+three+series.txt': 10152,\n"," '1238_the+city+of+dreadful+night.txt': 8978,\n"," '1240_the+playboy+of+the+western+world.txt': 12638,\n"," '12509_the+moon+rock.txt': 7687,\n"," '1261_betty+zane.txt': 2260,\n"," '1279_poems+and+songs+of+robert+burns.txt': 12007,\n"," '1280_spoon+river+anthology.txt': 8821,\n"," '1306_seven+men.txt': 7278,\n"," '1314_the+malefactor.txt': 9108,\n"," '1322_leaves+of+grass.txt': 12244,\n"," '13372_the+gloved+hand.txt': 440,\n"," '1366_the+cloister+and+the+hearth.txt': 2685,\n"," '13731_romance+island.txt': 2625,\n"," '13799_old+fires+and+profitable+ghosts+a.txt': 9276,\n"," '13801_harvest.txt': 6004,\n"," '13830_the+wreck+of+the+hesperus.txt': 5687,\n"," '1385_lin+mclean.txt': 10412,\n"," '1393_amours+de+voyage.txt': 6343,\n"," '14005_the+ladies+delight.txt': 12963,\n"," '14020_the+works+of+horace.txt': 13959,\n"," \"1413_tom+tiddler's+ground.txt\": 13923,\n"," '14145_if+winter+comes.txt': 11567,\n"," '14167_the+red+redmaynes.txt': 9393,\n"," \"1420_london's+underworld.txt\": 837,\n"," \"1421_mrs+lirriper's+legacy.txt\": 11121,\n"," '14256_the+bell+in+the+fog+and+other+stories.txt': 5044,\n"," '142_the+30000+dollar+bequest+and+other+stories.txt': 4234,\n"," '14347_plays+by+august+strindberg+second+series.txt': 12884,\n"," '14355_5440+or+fight.txt': 9701,\n"," '14449_dutch+courage+and+other+stories.txt': 2727,\n"," '1459_prufrock+and+other+observations.txt': 2066,\n"," '1460_the+black+dwarf.txt': 968,\n"," '1461_a+legend+of+montrose.txt': 10035,\n"," '14671_dorothy+vernon+of+haddon+hall.txt': 12586,\n"," '14712_vandover+and+the+brute.txt': 11609,\n"," '1473_the+absentee.txt': 11465,\n"," '14853_the+stowmarket+mystery+or+a+legacy+of+hate.txt': 4490,\n"," '14885_red+pottage.txt': 10374,\n"," '14896_the+diamond+master.txt': 10507,\n"," '15013_the+keeper+of+the+door.txt': 13847,\n"," '15081_the+tragedies+of+euripides.txt': 9433,\n"," '15120_the+broadway+anthology.txt': 7420,\n"," '151_the+rime+of+the+ancient+mariner.txt': 13804,\n"," '15265_the+quest+of+the+silver+fleece+a+novel.txt': 251,\n"," '15274_the+girl+from+montana.txt': 69,\n"," '15302_the+man+with+the+clubfoot.txt': 7382,\n"," '15368_fugitive+pieces.txt': 2407,\n"," '15591_a+woman+named+smith.txt': 5894,\n"," '15859_the+piazza+tales.txt': 10841,\n"," '15864_garman+and+worse+a+norwegian+novel.txt': 3164,\n"," '15865_noughts+and+crosses+stories+studies+and+sketches.txt': 9321,\n"," '1595_whirligigs.txt': 6630,\n"," '1606_kenilworth.txt': 6788,\n"," '16168_the+master+mystery.txt': 1539,\n"," '16169_the+tragedy+of+dido+queene+of+carthage.txt': 3451,\n"," \"16376_browning's+shorter+poems.txt\": 11361,\n"," '163_flower+fables.txt': 1388,\n"," '1646_roads+of+destiny.txt': 7313,\n"," '1654_an+unsocial+socialist.txt': 2298,\n"," '1655_the+god+of+his+fathers+tales+of+the+klondyke.txt': 4742,\n"," '16578_the+kipling+reader+selections+from+the.txt': 13225,\n"," '165_mcteague.txt': 683,\n"," '16659_translations+of+shakuntala+and+other+works.txt': 1083,\n"," '16692_beyond+the+rocks+a+love+story.txt': 8050,\n"," '1688_the+people+of+the+abyss.txt': 2462,\n"," '17026_craphound.txt': 5724,\n"," '17027_return+to+pleasure+island.txt': 40,\n"," '17029_shadow+of+the+mothaship.txt': 6287,\n"," '1703_dead+men+tell+no+tales.txt': 12843,\n"," '17063_a+lost+leader.txt': 12734,\n"," '1711_child+of+storm.txt': 2939,\n"," '1712_the+rescue+a+romance+of+the+shallows.txt': 2015,\n"," '1719_the+ballad+of+the+white+horse.txt': 926,\n"," \"17356_nobody's+man.txt\": 6493,\n"," '1745_the+poetical+works+of+john+milton.txt': 2332,\n"," '1754_the+seagull.txt': 8568,\n"," '1756_uncle+vanya.txt': 4011,\n"," '1758_majorie+daw.txt': 6564,\n"," '1760_the+man+who+could+not+lose.txt': 5690,\n"," '17620_the+point+of+honor+a+military+tale.txt': 3760,\n"," '17621_one+day+more+a+play+in+one+act.txt': 4398,\n"," '176_roderick+hudson.txt': 5425,\n"," '17860_stories+from+hans+andersen.txt': 5494,\n"," \"17891_evelina's+garden.txt\": 3322,\n"," '17938_contrary+mary.txt': 4198,\n"," '179_the+europeans.txt': 8936,\n"," '18259_gentle+julia.txt': 3365,\n"," '1840_the+financier+a+novel.txt': 3285,\n"," '18632_crossroads+of+destiny.txt': 13345,\n"," '18640_phineas+redux.txt': 8011,\n"," '18641_hunter+patrol.txt': 0,\n"," '1870_reginald+in+russia+and+other+sketches.txt': 2855,\n"," '18761_the+circular+study.txt': 7725,\n"," '1876_the+shape+of+fear.txt': 9563,\n"," '18800_last+enemy.txt': 6888,\n"," '18859_cross+purposes+and+the+shadows.txt': 167,\n"," '18861_temple+trouble.txt': 9147,\n"," '18883_the+four+feathers.txt': 8690,\n"," '19029_the+gifts+of+asti.txt': 10020,\n"," '19066_brigands+of+the+moon.txt': 5536,\n"," '19090_star+hunter.txt': 649,\n"," \"19146_the+entailed+hat+or+patty+cannon's+times.txt\": 4777,\n"," '1916_the+great+stone+face.txt': 7908,\n"," '19194_rebel+raider.txt': 1815,\n"," '19315_the+poems+of+giacomo+leopardi.txt': 11150,\n"," '19336_the+tangled+threads.txt': 6525,\n"," '19341_a+maker+of+history.txt': 1039,\n"," '19398_by+right+of+conquest+or+with+cortez+in+mexico.txt': 12322,\n"," '19403_murder+at+bridge.txt': 6240,\n"," '19459_born+again.txt': 4945,\n"," '19474_uller+uprising.txt': 1850,\n"," '19476_a+honeymoon+in+space.txt': 14022,\n"," '19500_can+you+forgive+her.txt': 10338,\n"," '19614_the+dark+forest.txt': 4607,\n"," '19978_35+sonnets.txt': 11351,\n"," '2002_sonnets+from+the+portuguese.txt': 13587,\n"," '2011_rudder+grange.txt': 3916,\n"," '20154_invaders+from+the+infinite.txt': 8590,\n"," '20179_the+ship+of+fools.txt': 2507,\n"," '20212_police+your+planet.txt': 477,\n"," '2025_my+lady+caprice.txt': 5608,\n"," '2037_novel+notes.txt': 9196,\n"," '20419_gigolo.txt': 7222,\n"," '20494_the+shrieking+pit.txt': 8200,\n"," '2062_all+for+love+or+the+world+well+lost+a+tragedy.txt': 3722,\n"," '20630_the+borough+treasurer.txt': 11654,\n"," '2070_to+the+last+man.txt': 542,\n"," '20719_under+the+country+sky.txt': 11790,\n"," '20727_the+cosmic+computer.txt': 509,\n"," '20732_the+carmina+of+caius+valerius+catullus.txt': 4032,\n"," '20796_the+colors+of+space.txt': 7977,\n"," '20911_the+rose+of+old+st+louis.txt': 12669,\n"," '20_paradise+lost.txt': 3560,\n"," '21040_brazilian+tales.txt': 9065,\n"," '2126_the+quest+of+the+sacred+slipper.txt': 13554,\n"," '21279_2+b+r+0+2+b.txt': 7501,\n"," '21350_ralph+roister+doister.txt': 8474,\n"," \"21415_the+young+visiters+or+mr+salteena's+plan.txt\": 7467,\n"," '21530_the+angel+of+terror.txt': 2903,\n"," '21576_the+privateersman.txt': 10585,\n"," '21579_snarleyyow+or+the+dog+fiend.txt': 13747,\n"," '21647_subspace+survivors.txt': 12381,\n"," '21773_four+meetings.txt': 6426,\n"," '21892_at+the+time+appointed.txt': 12085,\n"," '21897_an+incident+on+route+12.txt': 7903,\n"," '21904_the+millionaire+baby.txt': 6149,\n"," '21932_embarrassments.txt': 5190,\n"," '22002_a+simple+story.txt': 7604,\n"," '22132_giants+on+the+earth.txt': 6388,\n"," '22173_the+grell+mystery.txt': 7817,\n"," \"22218_the+street+that+wasn't+there.txt\": 2000,\n"," '222_moon+and+sixpence.txt': 5781,\n"," '22357_danger+and+other+stories.txt': 1265,\n"," '22467_sand+doom.txt': 4366,\n"," '22470_the+bell+tone.txt': 11286,\n"," \"22538_the+devil's+asteroid.txt\": 206,\n"," '22541_the+misplaced+battleship.txt': 7439,\n"," '22545_warning+from+the+stars.txt': 10449,\n"," '22560_the+worshippers.txt': 8798,\n"," '22579_bread+overhead.txt': 287,\n"," '22629_the+vortex+blaster.txt': 10547,\n"," '22754_masters+of+space.txt': 6706,\n"," '22867_meeting+of+the+board.txt': 634,\n"," '22869_the+dark+door.txt': 815,\n"," '2289_rosmersholm.txt': 11906,\n"," '22967_the+stoker+and+the+stars.txt': 4354,\n"," '2296_pillars+of+society.txt': 7555,\n"," '23028_greylorn.txt': 7249,\n"," '23104_the+blue+tower.txt': 377,\n"," '23146_and+all+the+earth+a+grave.txt': 13357,\n"," '23153_the+big+bounce.txt': 30,\n"," \"23160_solomon's+orbit.txt\": 12628,\n"," '23210_missing+link.txt': 9882,\n"," '23232_the+servant+problem.txt': 3694,\n"," \"23433_the+kitten's+garden+of+verses.txt\": 245,\n"," '23489_godfrey+morgan+a+californian+mystery.txt': 9645,\n"," '23509_the+beast+of+space.txt': 3548,\n"," '23597_beauties+of+tennyson.txt': 9139,\n"," '2360_the+riddle+of+the+sands.txt': 1113,\n"," '23688_the+indulgence+of+negu+mah.txt': 2115,\n"," '23727_the+lost+girl.txt': 6075,\n"," '23753_the+diverting+history+of+john+gilpin.txt': 11452,\n"," '23789_cruel+as+the+grave.txt': 11308,\n"," '23810_at+fault.txt': 4693,\n"," '2381_actions+and+reactions.txt': 13602,\n"," '23868_vanishing+point.txt': 5280,\n"," '24020_romola.txt': 4281,\n"," \"24118_we+didn't+do+anything+wrong+hardly.txt\": 9935,\n"," '24149_the+ambulance+made+two+trips.txt': 13324,\n"," '24161_all+day+september.txt': 13093,\n"," '24246_greener+than+you+think.txt': 10115,\n"," '24274_the+native+soil.txt': 7884,\n"," '24280_endymion+a+poetic+romance.txt': 8501,\n"," '24313_once+a+week.txt': 13719,\n"," '24349_coming+home+1916.txt': 7349,\n"," '246_the+rubaiyat+of+omar+khayyam.txt': 1163,\n"," '24751_the+kitchen+cat+and+other+stories.txt': 7194,\n"," '24761_the+rivals+a+comedy.txt': 1346,\n"," '24769_the+opal+serpent.txt': 9899,\n"," '24876_lucy+maud+montgomery+short+stories+1905+to+1906.txt': 8726,\n"," '24927_a+matter+of+magnitude.txt': 12957,\n"," '24949_control+group.txt': 7674,\n"," '24966_survival+tactics.txt': 9185,\n"," '24977_the+perfectionists.txt': 2053,\n"," '25017_a+son+of+the+immortals.txt': 9940,\n"," '2502_chitra+a+play+in+one+act.txt': 6666,\n"," '25078_no+moving.txt': 2147,\n"," '25153_tales+of+a+wayside+inn.txt': 4551,\n"," '25344_the+scarlet+letter.txt': 12175,\n"," '2545_when+god+laughs+and+other+stories.txt': 11403,\n"," '25546_songs+of+a+sourdough.txt': 11012,\n"," '25586_a+collection+of+stories+reviews+and+essays.txt': 13675,\n"," '25629_postmark+ganymede.txt': 13316,\n"," '25727_vagabondia+1884.txt': 11955,\n"," '257_troilus+and+criseyde.txt': 10698,\n"," '259_ballads+of+a+cheechako.txt': 1576,\n"," '26001_the+bertrams.txt': 6588,\n"," '2600_war+and+peace.txt': 8650,\n"," '26206_pandemic.txt': 9682,\n"," \"26259_her+mother's+secret.txt\": 6456,\n"," '26292_the+star+hyacinths.txt': 3132,\n"," '26447_the+strange+case+of+mortimer+fenley.txt': 1779,\n"," \"26741_i'm+a+stranger+here+myself.txt\": 9179,\n"," '26772_a+question+of+courage.txt': 2125,\n"," '2681_ten+years+later.txt': 7848,\n"," \"26867_john+jones's+dollar.txt\": 2208,\n"," '2688_the+clue+of+the+twisted+candle.txt': 2076,\n"," '26955_advanced+chemistry.txt': 1229,\n"," '26967_the+coming+of+the+ice.txt': 2669,\n"," '27176_more+beasts+for+worse+children.txt': 11045,\n"," '27392_lease+to+doomsday.txt': 13269,\n"," '27424_cautionary+tales+for+children.txt': 2827,\n"," '2753_ali+pacha+celebrated+crimes.txt': 754,\n"," '2758_marquise+de+ganges+celebrated+crimes.txt': 13874,\n"," '2759_the+man+in+the+iron+mask.txt': 5001,\n"," '2760_celebrated+crimes.txt': 7104,\n"," '2765_the+lady+from+the+sea.txt': 5172,\n"," \"2767_the+devil's+paw.txt\": 344,\n"," '27781_revised+edition+of+poems.txt': 4125,\n"," '2785_the+elusive+pimpernel.txt': 11743,\n"," '27990_theo+a+sprightly+love+story.txt': 1496,\n"," '28062_the+man+who+saw+the+future.txt': 8093,\n"," '28063_the+next+logical+step.txt': 8275,\n"," '28084_malcolm+sage+detective.txt': 888,\n"," '28119_my+father+the+cat.txt': 6381,\n"," '28161_the+master+mummer.txt': 4460,\n"," '28218_three+unpublished+poems.txt': 6336,\n"," '28264_cleek+the+master+detective.txt': 11863,\n"," '28287_the+lady+of+the+lake.txt': 3798,\n"," '28451_i+like+martian+music.txt': 2201,\n"," '28453_flight+through+tomorrow.txt': 5977,\n"," '28488_tartuffe+or+the+hypocrite.txt': 6317,\n"," '28516_the+saracen+the+holy+war.txt': 4091,\n"," '28583_the+calm+man.txt': 12572,\n"," '28636_the+grey+woman+and+other+tales.txt': 9817,\n"," '28647_texas+week.txt': 6452,\n"," '28650_year+of+the+big+thaw.txt': 8970,\n"," '28665_sea+garden.txt': 2992,\n"," '28862_the+time+of+roses.txt': 13814,\n"," '28903_all+that+matters.txt': 13147,\n"," '28988_jennie+gerhardt+a+novel.txt': 6041,\n"," '29133_shipwreck+in+the+sky.txt': 12949,\n"," '29159_acid+bath.txt': 9052,\n"," '29271_the+issahar+artifacts.txt': 11048,\n"," '29345_mountain+interval.txt': 8768,\n"," '29353_vampires+of+space.txt': 2834,\n"," '29445_the+hour+of+battle.txt': 7528,\n"," '29452_the+wings+of+the+dove.txt': 8999,\n"," '29548_warrior+race.txt': 13948,\n"," \"29890_the+doctor's+family.txt\": 8369,\n"," \"30012_l'aiglon.txt\": 11434,\n"," '30045_planet+of+dreams.txt': 4902,\n"," '30140_gone+fishing.txt': 11212,\n"," \"30199_mcilvaine's+star.txt\": 300,\n"," '30234_dead+ringer.txt': 234,\n"," '30236_pepita+ximenez.txt': 6932,\n"," '30240_the+big+trip+up+yonder.txt': 9311,\n"," '3026_north+of+boston.txt': 13284,\n"," '30276_some+imagist+poets+an+anthology.txt': 10277,\n"," '30302_the+benefactress.txt': 1623,\n"," '30334_ultima+thule.txt': 12761,\n"," '30477_the+sign+of+silence.txt': 4909,\n"," '30488_the+green+helmet+and+other+poems.txt': 8920,\n"," \"30715_where+there's+hope.txt\": 6582,\n"," '30723_fathers+and+children.txt': 3872,\n"," '30730_the+hound+of+heaven.txt': 8629,\n"," '30960_the+people+of+the+crater.txt': 5750,\n"," '3166_doctor+thorne.txt': 13397,\n"," '31_oedipus+trilogy.txt': 13108,\n"," '32324_sam+this+is+you.txt': 7509,\n"," '32436_duel+on+syrtis.txt': 11291,\n"," '3258_a+laodicean+a+story+of+today.txt': 5086,\n"," '325_phantastes+a+faerie+romance+for+men+and+women.txt': 4645,\n"," \"32732_jacob's+ladder.txt\": 1674,\n"," \"328_a+heap+o'+livin'.txt\": 5817,\n"," '3328_man+and+superman.txt': 3214,\n"," '3486_the+inca+of+perusalem.txt': 106,\n"," '3487_augustus+does+his+bit.txt': 5985,\n"," '3490_the+admirable+crichton.txt': 7954,\n"," '35171_the+trojan+women+of+euripides.txt': 12817,\n"," '353_in+flanders+fields+and+other+poems.txt': 4416,\n"," '3543_heartbreak+house.txt': 1711,\n"," \"362_miss+billy's+decision.txt\": 12145,\n"," \"3638_the+devil's+disciple.txt\": 5467,\n"," '36773_oxford+lectures+on+poetry.txt': 13492,\n"," '3692_the+house+of+life.txt': 12484,\n"," '3694_every+man+in+his+humour.txt': 9522,\n"," '3695_every+man+out+of+his+humour.txt': 5562,\n"," '3698_the+task+and+other+poems.txt': 5358,\n"," '3715_the+parenticide+club.txt': 10299,\n"," '372_prince+otto+a+romance.txt': 128,\n"," '3753_peacock+pie+a.txt': 12548,\n"," '375_an+occurrence+at+owl+creek+bridge.txt': 11456,\n"," '380_weir+of+hermiston.txt': 13004,\n"," '391_the+song+of+roland.txt': 10789,\n"," \"397_l'allegro+il+penseroso+comus+and+lycidas.txt\": 11713,\n"," '400_helen+of+troy+and+other+poems.txt': 11926,\n"," '4011_epicoene+or+the+silent+woman.txt': 10228,\n"," '4023_candida.txt': 12789,\n"," '4025_anna+christie.txt': 11544,\n"," '4070_the+master+builder.txt': 11690,\n"," '4071_monsieur+lecoq.txt': 5937,\n"," '4081_the+alchemist.txt': 9238,\n"," '4097_alice+of+old+vincennes.txt': 7767,\n"," '409_poems+on+various+subjects+religious+and+moral.txt': 3006,\n"," '4207_aesthetic+poetry.txt': 432,\n"," '421_kidnapped.txt': 6734,\n"," '422_the+romany+rye.txt': 2768,\n"," '4253_dramatic+romances.txt': 3046,\n"," '4357_american+fairy+tales.txt': 1457,\n"," '4368_flappers+and+philosophers.txt': 6852,\n"," '4378_in+homespun.txt': 577,\n"," '456_the+door+in+the+wall+and+other+stories.txt': 9735,\n"," '463_the+red+badge+of+courage.txt': 311,\n"," '4684_the+u+p+trail.txt': 8281,\n"," '4745_at+the+villa+rose.txt': 8245,\n"," \"4767_the+mayor's+wife.txt\": 5240,\n"," '487_songs+of+travel.txt': 12462,\n"," '489_one+basket.txt': 11832,\n"," '506_the+shuttle.txt': 9974,\n"," '5091_the+tempting+of+tavernake.txt': 12515,\n"," '512_mosses+from+an+old+manse+and+other+stories.txt': 2573,\n"," '5142_graustark.txt': 5139,\n"," '515_margret+howth+a+story+of+today.txt': 6195,\n"," '5167_the+countess+cathleen.txt': 2438,\n"," '5182_the+old+english+baron+a+gothic+story.txt': 7047,\n"," \"553_out+of+time's+abyss.txt\": 8872,\n"," '5625_flint+and+feather.txt': 11058,\n"," '5723_press+cuttings.txt': 7534,\n"," '5815_the+great+impersonation.txt': 3954,\n"," '5897_castle+richmond.txt': 1306,\n"," '58_paradise+regained.txt': 8107,\n"," '591_flame+and+shadow.txt': 1065,\n"," '596_rivers+to+the+sea.txt': 12977,\n"," '60_the+scarlet+pimpernel.txt': 3408,\n"," '6782_the+robbers.txt': 5649,\n"," '6786_the+piccolomini.txt': 9366,\n"," '6788_wilhelm+tell.txt': 3987,\n"," '6790_demetrius.txt': 1235,\n"," '680_the+golden+threshold.txt': 10317,\n"," '689_the+kreutzer+sonata+and+other+stories.txt': 2164,\n"," '701_the+king+of+the+golden+river.txt': 6682,\n"," '704_the+mansion.txt': 8419,\n"," '7155_the+prince+and+the+pauper.txt': 10569,\n"," '715_the+moon+endureth+tales+and+fancies.txt': 10930,\n"," '7164_gitanjali.txt': 1195,\n"," '718_tono+bungay.txt': 13176,\n"," '7471_the+man+with+two+left+feet+and+other+stories.txt': 4518,\n"," '768_wuthering+heights.txt': 3497,\n"," '7805_first+plays.txt': 11520,\n"," '8123_the+virginians.txt': 12412,\n"," '82_ivanhoe.txt': 4821,\n"," '866_the+cost+of+kindness.txt': 5679,\n"," \"868_the+philosopher's+joke.txt\": 7588,\n"," '8875_the+road+to+damascus.txt': 3259,\n"," '8897_nina+balatka.txt': 7006,\n"," '901_the+jew+of+malta.txt': 5331,\n"," \"917_barnaby+rudge+a+tale+of+the+riots+of+'eighty.txt\": 8148,\n"," '9182_villette.txt': 10465,\n"," '932_the+fall+of+the+house+of+usher.txt': 3114,\n"," '963_little+dorrit.txt': 13634,\n"," '9807_scarhaven+keep.txt': 11248,\n"," '980_alice+adams.txt': 10890,\n"," '9869_the+confession+of+a+child+of+the+century.txt': 1896,\n"," '9902_the+middle+of+things.txt': 13364,\n"," '9923_the+box+with+broken+seals.txt': 8440,\n"," '995_ballads+of+a+bohemian.txt': 721,\n"," '9989_bees+in+amber+a+little.txt': 13053}"]},"execution_count":40,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["start_of_segmented_book"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":8097,"status":"ok","timestamp":1623116464702,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"XZf01knMQxBC","outputId":"f8ea0269-64a8-494e-c64a-7c2685bcc8bd"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"149818d96ad34992a498bdc4bd6d3a5d","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# When batched = True, we take in multiple examples\n","def filter_segments(example, idx):\n","  if (idx - start_of_segmented_book[example['book_title']] \u003c 40):\n","    return True\n","  else:\n","    return False\n","\n","test = chunked_encoded_dataset['train'].filter(filter_segments, with_indices = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1623116562933,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"jKhzZkSfR9Bk","outputId":"6ab79a96-ede5-46cb-8e6b-549d3c710a82"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["num_segments_per_book = [len(list(g[1])) for g in itertools.groupby(test['book_title'])]\n","\n","plt.hist(num_segments_per_book, density=True, bins=30)  # density=False would make counts\n","plt.ylabel('Probability')\n","plt.xlabel('Data');"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"elapsed":7999,"status":"ok","timestamp":1623116622079,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"MYj8PW1JSedZ","outputId":"bfa5f835-9575-4b4c-c505-b3728dee52e2"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"941d360ac00d434b97a0774840cb03ee","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["chunked_encoded_dataset['train'] = chunked_encoded_dataset['train'].filter(filter_segments, with_indices = True)"]},{"cell_type":"markdown","metadata":{"id":"_5umzDNpkQuo"},"source":["# GoodReads Success Prediction"]},{"cell_type":"markdown","metadata":{"id":"a3G544UU9O2O"},"source":["## Transformer --\u003e Classification"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":53549,"status":"ok","timestamp":1628971810803,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"lAlIUr2KUlhm","outputId":"6dfe4714-b695-40e5-8547-618fd0e1bb50"},"outputs":[{"name":"stdout","output_type":"stream","text":["standard model microsoft/deberta-base\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57335874541f490c8e74399efce2f070","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/559M [00:00\u003c?, ?B/s]"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['config', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from MultiTaskExtensions import DistilBERTForMultipleSequenceClassification\n","from transformers import DistilBertConfig\n","pretrained_model_name_or_path = config['Model']['name']\n","\n","if (eval(config['WandB']['use_WandB_pretrained'])):\n","  run = wandb.init()\n","  artifact = run.use_artifact('lucaguarro/goodreads_success_predictor/model-1fajaalf:v0', type='model')\n","  pretrained_model_name_or_path = artifact.download()\n","\n","if (eval(config['Model']['multi_task'])):\n","  metric_for_best_model = 'eval_s_f1'\n","  if (config['Model']['name'] == 'distilbert-base-uncased'):\n","    from MultiTaskExtensions import DistilBERTForMultipleSequenceClassification\n","    db_config = DistilBertConfig.from_pretrained(pretrained_model_name_or_path)\n","    db_config.update({'_name_or_path': pretrained_model_name_or_path, 'alpha': 0.5})\n","    print(db_config)\n","    model = DistilBERTForMultipleSequenceClassification.from_pretrained(pretrained_model_name_or_path = db_config._name_or_path, config = db_config)\n","  else:\n","    from MultiTaskExtensions import BertForMultipleSequenceClassification\n","    model = BertForMultipleSequenceClassification.from_pretrained(pretrained_model_name_or_path)\n","\n","else:\n","  print(\"standard model\", pretrained_model_name_or_path)\n","  metric_for_best_model = 'eval_f1'\n","  model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path)\n","  model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"O_L9eX3a6NBS"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_PROJECT=goodreads_success_predictor_80_20\n"]},{"name":"stderr","output_type":"stream","text":["The following columns in the training set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: genre, book_title.\n","***** Running training *****\n","  Num examples = 22639\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed \u0026 accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1415\n","Automatic Weights \u0026 Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlucaguarro\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                Tracking run with wandb version 0.12.0\u003cbr/\u003e\n","                Syncing run \u003cstrong style=\"color:#cdcd00\"\u003egoodreads_success_predictor_80_20_DeBERTa\u003c/strong\u003e to \u003ca href=\"https://wandb.ai\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e \u003ca href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\"\u003e(Documentation)\u003c/a\u003e.\u003cbr/\u003e\n","                Project page: \u003ca href=\"https://wandb.ai/lucaguarro/goodreads_success_predictor_80_20\" target=\"_blank\"\u003ehttps://wandb.ai/lucaguarro/goodreads_success_predictor_80_20\u003c/a\u003e\u003cbr/\u003e\n","                Run page: \u003ca href=\"https://wandb.ai/lucaguarro/goodreads_success_predictor_80_20/runs/1mouyy0g\" target=\"_blank\"\u003ehttps://wandb.ai/lucaguarro/goodreads_success_predictor_80_20/runs/1mouyy0g\u003c/a\u003e\u003cbr/\u003e\n","                Run data is saved locally in \u003ccode\u003e/content/wandb/run-20210814_201115-1mouyy0g\u003c/code\u003e\u003cbr/\u003e\u003cbr/\u003e\n","            "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-17-9471c4951cf3\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 34\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1287\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1782\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1814\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1148\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m         )\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 920\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         )\n\u001b[1;32m    922\u001b[0m         \u001b[0mencoded_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 415\u001b[0;31m                 \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m             )\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, return_att, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 338\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_att\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, return_att, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 271\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_att\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, return_att, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 599\u001b[0;31m             \u001b[0mrel_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisentangled_att_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrel_att\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mdisentangled_att_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mp2c_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_query_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             p2c_att = torch.gather(\n\u001b[0;32m--\u003e 669\u001b[0;31m                 \u001b[0mp2c_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2c_dynamic_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2c_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             ).transpose(-1, -2)\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 15.90 GiB total capacity; 14.86 GiB already allocated; 115.75 MiB free; 14.89 GiB reserved in total by PyTorch)"]}],"source":["%env WANDB_PROJECT=goodreads_success_predictor_80_20\n","\n","training_args = TrainingArguments(\n","    'goodreads_success_predictor_80_20_DeBERTa',\n","    # output_dir='./results',          # output directory\n","    num_train_epochs=1,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    learning_rate=0.00005,\n","    per_device_eval_batch_size=32,   # batch size for evaluation\n","    warmup_steps=19,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    # logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n","    # gradient_accumulation_steps=2,\n","    evaluation_strategy = \"steps\",\n","    eval_steps = 10, # prob better if set to 601 that way it evenly divides into the epochs\n","    load_best_model_at_end = True,\n","    metric_for_best_model = 'eval_s_f1',\n","    greater_is_better = True,\n","    report_to = \"wandb\",\n","    save_total_limit = 5\n","    # learning rate, play around with weight_decay\n","    # select best model (and not the last one); use validation loss to pick the best model\n",")\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=chunked_encoded_dataset['train'],         # training dataset             # evaluation dataset\n","    eval_dataset=chunked_encoded_dataset['validation'], \n","    compute_metrics = compute_metrics\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1628899282777,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"JpBjjjgA9oEM","outputId":"0daf1406-8832-4a38-df67-7e097a4becda"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 22639\n","    })\n","    validation: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 5482\n","    })\n","    test: Dataset({\n","        features: ['attention_mask', 'book_title', 'genre', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 11278\n","    })\n","})"]},"execution_count":28,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["chunked_encoded_dataset"]},{"cell_type":"markdown","metadata":{"id":"lq8akyvCLgHA"},"source":["## Scorer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHVlCz50L9Q-"},"outputs":[],"source":["from MultiTaskExtensions import DistilBERTForMultipleSequenceClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"elapsed":10958,"status":"ok","timestamp":1628265544590,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"u0aBRyJkLpAr","outputId":"1f197948-7fc2-40ab-b2d4-2c8d7054e639"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlucaguarro\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["\n","                Tracking run with wandb version 0.11.2\u003cbr/\u003e\n","                Syncing run \u003cstrong style=\"color:#cdcd00\"\u003esnowy-snowball-205\u003c/strong\u003e to \u003ca href=\"https://wandb.ai\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e \u003ca href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\"\u003e(Documentation)\u003c/a\u003e.\u003cbr/\u003e\n","                Project page: \u003ca href=\"https://wandb.ai/lucaguarro/goodreads_success_predictor\" target=\"_blank\"\u003ehttps://wandb.ai/lucaguarro/goodreads_success_predictor\u003c/a\u003e\u003cbr/\u003e\n","                Run page: \u003ca href=\"https://wandb.ai/lucaguarro/goodreads_success_predictor/runs/27coihiw\" target=\"_blank\"\u003ehttps://wandb.ai/lucaguarro/goodreads_success_predictor/runs/27coihiw\u003c/a\u003e\u003cbr/\u003e\n","                Run data is saved locally in \u003ccode\u003e/content/wandb/run-20210806_155852-27coihiw\u003c/code\u003e\u003cbr/\u003e\u003cbr/\u003e\n","            "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-3igwy2id:v0, 255.48MB. 3 files... Done. 0:0:0\n"]}],"source":["run = wandb.init()\n","artifact = run.use_artifact('lucaguarro/DistilbertMultitaskHPSearch/model-3igwy2id:v0', type='model')\n","artifact_dir = artifact.download()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7152,"status":"ok","timestamp":1628265555128,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"iWM8FcKeL5Dq","outputId":"f96217c3-8edf-412d-b3be-614d2f325125"},"outputs":[{"name":"stdout","output_type":"stream","text":["2 8\n"]}],"source":["model = DistilBERTForMultipleSequenceClassification.from_pretrained(artifact_dir)\n","trainer = Trainer(\n","    model=model\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adteyeUzMQS4"},"outputs":[],"source":["from scores import ModelScorer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":159443,"status":"ok","timestamp":1628265791163,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"33qPNFMTMVUr","outputId":"ecc01c96-fddf-4614-dc95-fd9937704eb3"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `DistilBERTForMultipleSequenceClassification.forward` and have been ignored: book_title, token_type_ids.\n","***** Running Prediction *****\n","  Num examples = 5236\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["Getting predictions on validation set\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='2007' max='655' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [655/655 02:39]\n","    \u003c/div\u003e\n","    "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `DistilBERTForMultipleSequenceClassification.forward` and have been ignored: book_title, token_type_ids.\n","***** Running Prediction *****\n","  Num examples = 10816\n","  Batch size = 8\n"]},{"name":"stdout","output_type":"stream","text":["Getting predictions on test set\n"]}],"source":["m_scorer = ModelScorer(trainer, chunked_encoded_dataset, for_multitask=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdWwDnkNMi1D"},"outputs":[],"source":["m_scorer.get_segmented_f1_scores()"]},{"cell_type":"markdown","metadata":{"id":"2FCxHJtLFUOP"},"source":["# Hyperparameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"2hd8wn9jdjfV"},"source":["multitask hyperparameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1628266962072,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"fwq2YV_dqo5j","outputId":"6ad7554c-2e66-42b8-c43c-906e29ea1bdf"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlucaguarro\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"name":"stdout","output_type":"stream","text":["env: WANDB_LOG_MODEL=true\n","env: WANDB_PROJECT=DistilbertMultitaskHPSearch\n"]}],"source":["# saves our models to artifacts in WandB\n","%env WANDB_LOG_MODEL=true\n","wandb.login()\n","%env WANDB_PROJECT=DistilbertMultitaskHPSearch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1628266964274,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"EgFdAxweCbfj","outputId":"ab6e67f8-b899-4ee2-a7a4-085998e448de"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['attention_mask', 'book_title', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 21539\n","    })\n","    validation: Dataset({\n","        features: ['attention_mask', 'book_title', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 5236\n","    })\n","    test: Dataset({\n","        features: ['attention_mask', 'book_title', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 10816\n","    })\n","})"]},"execution_count":20,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["chunked_encoded_dataset"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":763,"status":"ok","timestamp":1628971861255,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"IObtn-HBeB68","outputId":"150a3da2-ee47-4829-c215-01dc721199e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["single\n"]}],"source":["def compute_metrics_single(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","def compute_metrics_multi(pred):\n","    preds = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    success_labels = label_ids[:, 0]\n","    genre_labels = label_ids[:, 1]\n","\n","    success_preds = preds[:, 0:2].argmax(1)\n","    genre_preds = preds[:, 2:6].argmax(1)\n","\n","    s_precision, s_recall, s_f1, _ = precision_recall_fscore_support(success_labels, success_preds, average='weighted')\n","    s_acc = accuracy_score(success_labels, success_preds)\n","\n","    g_precision, g_recall, g_f1, _ = precision_recall_fscore_support(genre_labels, genre_preds, average='weighted')\n","    g_acc = accuracy_score(success_labels, success_preds)\n","\n","    return {\n","        's_accuracy': s_acc,\n","        's_f1': s_f1,\n","        's_precision': s_precision,\n","        's_recall': s_recall,\n","        'g_accuracy': g_acc,\n","        'g_f1': g_f1,\n","        'g_precision': g_precision,\n","        'g_recall': g_recall\n","    }\n","\n","if eval(config['Model']['multi_task']):\n","  print('multi')\n","  # from scores import compute_metrics_multi\n","  compute_metrics = compute_metrics_multi\n","else:\n","  print('single')\n","  # from scores import compute_metrics_single\n","  compute_metrics = compute_metrics_single\n","\n","def my_objective(metrics):\n","    # Your elaborate computation here\n","    if eval(config['Model']['multi_task']):\n","      return metrics['eval_s_f1']\n","    else:\n","      return metrics['eval_f1']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cgd-ZnB6VFv8"},"outputs":[],"source":["db_config_base = DistilBertConfig.from_pretrained('/content/drive/MyDrive/Thesis/BookSuccessPredictor/saved_models/DistilBertPretrained')\n","db_config_base.update({'_name_or_path': '/content/drive/MyDrive/Thesis/BookSuccessPredictor/saved_models/DistilBertPretrained', 'alpha': 0.2, 'dropout': 0.8})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1628266992360,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"PRbq_rU8Rovj","outputId":"67586ea2-d9eb-4529-900e-679ebdd38c74"},"outputs":[{"data":{"text/plain":["DistilBertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Thesis/BookSuccessPredictor/saved_models/DistilBertPretrained\",\n","  \"activation\": \"gelu\",\n","  \"alpha\": 0.2,\n","  \"architectures\": [\n","    \"DistilBertModel\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.8,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.10.0.dev0\",\n","  \"vocab_size\": 30523\n","}"]},"execution_count":23,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["db_config_base"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"executionInfo":{"elapsed":457,"status":"error","timestamp":1626889589453,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"zqQMbfUM1mmK","outputId":"8e0514c1-2a28-45e9-a588-1f12bc211f03"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-20-f15d557163ec\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBERTForMultipleSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_config_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_config_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'DistilBERTForMultipleSequenceClassification' is not defined"]}],"source":["test = DistilBERTForMultipleSequenceClassification.from_pretrained(pretrained_model_name_or_path = db_config_base._name_or_path, config = db_config_base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zG1m6btWJ2jg"},"outputs":[],"source":["# tune_config_pop_based = {\n","#     \"per_device_train_batch_size\": 16,\n","#     \"per_device_eval_batch_size\": 32,\n","#     \"num_train_epochs\": 1,\n","#     \"max_steps\": 1 if smoke_test else -1,  # Used for smoke test.\n","#     \"wandb\": {\n","#         \"project\": \"DistilbertMultitaskHPSearch\",\n","#         \"group\": \"Search1\",\n","#         \"api_key\": \"XXXXXXXX\",\n","#         \"log_config\": True\n","#     }\n","# }\n","\n","# scheduler = PopulationBasedTraining(\n","#     time_attr=\"training_iteration\",\n","#     metric=\"eval_s_f1\",\n","#     mode=\"max\",\n","#     perturbation_interval=60,\n","#     hyperparam_mutations={\n","#         \"weight_decay\": tune.uniform(0.0, 0.3),\n","#         \"learning_rate\": tune.uniform(1e-5, 5e-5),\n","#         \"per_device_train_batch_size\": [16],\n","#     })"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cPueEVqH18lD"},"outputs":[],"source":["from transformers.modeling_outputs import SequenceClassifierOutput\n","from torch import nn\n","import torch\n","from torch.nn import CrossEntropyLoss, MSELoss\n","\n","from transformers import DistilBertPreTrainedModel, DistilBertModel\n","class DistilBERTForMultipleSequenceClassification(DistilBertPreTrainedModel):\n","    def __init__(self, config, num_labels1 = 2, num_labels2 = 8):\n","        super().__init__(config)\n","        self.num_labels1 = num_labels1\n","        self.num_labels2 = num_labels2\n","        print(self.num_labels1, self.num_labels2)\n","        self.alpha = config.alpha\n","        self.config = config\n","\n","        self.distilbert = DistilBertModel(config)\n","        self.pre_classifier = nn.Linear(config.dim, config.dim)\n","        self.classifier1 = nn.Linear(config.dim, self.num_labels1)\n","        self.classifier2 = nn.Linear(config.dim, self.num_labels2)\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","        self.init_weights()\n","\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n","            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n","            If :obj:`config.num_labels \u003e 1` a classification loss is computed (Cross-Entropy).\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        distilbert_output = self.distilbert(\n","              input_ids=input_ids,\n","              attention_mask=attention_mask,\n","              head_mask=head_mask,\n","              inputs_embeds=inputs_embeds,\n","              output_attentions=output_attentions,\n","              output_hidden_states=output_hidden_states,\n","              return_dict=return_dict,\n","          )\n","        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n","        pooled_output = hidden_state[:, 0]  # (bs, dim)\n","        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n","        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n","        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n","        logits1 = self.classifier1(pooled_output)\n","        logits2 = self.classifier2(pooled_output)\n","        logits = torch.cat([logits1, logits2], 1)\n","\n","        loss = None\n","        if labels is not None:\n","            #if self.config.problem_type is None:\n","            #self.config.problem_type = \"single_label_classification\"\n","            \n","            if self.num_labels1 \u003e 1:\n","                loss_fct1 = CrossEntropyLoss()\n","                loss1 = loss_fct1(logits1.view(-1, self.num_labels1), labels[:, 0].view(-1))\n","            else:\n","                loss_fct1 = MSELoss()\n","                loss1 = loss_fct1(logits1.view(-1), labels[:, 0].view(-1))\n","\n","            if self.num_labels2 \u003e 1:\n","                loss_fct2 = CrossEntropyLoss()\n","                loss2 = loss_fct2(logits2.view(-1, self.num_labels2), labels[:, 1].view(-1))\n","            else:\n","                loss_fct2 = MSELoss()\n","                loss2 = loss_fct2(logits2.view(-1), labels[:, 1].view(-1))\n","            loss = self.alpha*loss1 + (1-self.alpha)*loss2 \n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:] #not sure if this works\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=distilbert_output.hidden_states, #hidden_states,\n","            attentions=distilbert_output.attentions, #attentions,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8HR2WV3iFRz"},"outputs":[],"source":["def tune_transformer(num_samples=8, gpus_per_trial=0, smoke_test=False):\n","    data_dir_name = \"./data\" if not smoke_test else \"./test_data\"\n","    data_dir = os.path.abspath(os.path.join(os.getcwd(), data_dir_name))\n","    if not os.path.exists(data_dir):\n","        os.mkdir(data_dir, 0o755)\n","\n","    def get_model(params):\n","        db_config = db_config_base\n","        print(\"printing params\", params)\n","        if params is not None:\n","          db_config.update({'_name_or_path': '/content/drive/MyDrive/Thesis/BookSuccessPredictor/saved_models/DistilBertPretrained', 'alpha': params['alpha'], 'attention_dropout': params['attention_dropout'], 'dropout': params['dropout']})\n","        return DistilBERTForMultipleSequenceClassification.from_pretrained(pretrained_model_name_or_path = db_config_base._name_or_path, config = db_config_base)\n","\n","    train_dataset = chunked_encoded_dataset['train']\n","    eval_dataset = chunked_encoded_dataset['validation']\n","\n","    training_args = TrainingArguments(\n","        output_dir=\"DistilBertMultitask_HPsearch\",\n","        learning_rate=1e-5,  # config\n","        do_train=True,\n","        do_eval=True,\n","        no_cuda=gpus_per_trial \u003c= 0,\n","        evaluation_strategy=\"steps\",\n","        save_total_limit = 5,\n","        logging_strategy=\"steps\",\n","        logging_steps=5,\n","        eval_steps=5,\n","        load_best_model_at_end=True,\n","        # metric_for_best_model='eval_s_f1',\n","        # greater_is_better=True,\n","        num_train_epochs=0.9,  # config\n","        per_device_train_batch_size=16,  # config\n","        per_device_eval_batch_size=16,  # config\n","        warmup_steps=0,\n","        weight_decay=0.1,  # config\n","        logging_dir=\"./logs\",\n","        skip_memory_metrics=True)\n","\n","    tune_config_ASHA = {\n","        \"attention_dropout\": tune.uniform(0.15,0.4),\n","        \"dropout\": tune.uniform(0.15, 0.4),\n","        \"alpha\": tune.uniform(0.3,0.7),\n","        \"learning_rate\": tune.loguniform(1e-5, 1e-4),\n","        \"per_device_train_batch_size\": tune.choice([16]),\n","        \"num_train_epochs\": tune.choice([0.9]),\n","        \"wandb\": {\n","            \"project\": \"DistilbertMultitaskHPSearch\",\n","            \"group\": \"Search1\",\n","            \"api_key\": config['WandB']['api_key'],\n","            \"log_config\": True\n","        }\n","    }\n","\n","    trainer = Trainer(\n","        model_init=get_model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics)\n","    \n","\n","    # scheduler = ASHAScheduler(\n","    #     metric=\"eval_s_f1\",\n","    #     mode=\"max\",\n","    #     max_t=1000,\n","    #     grace_period=30,\n","    #     reduction_factor=1.5)\n","\n","    # scheduler = ASHAScheduler(\n","    #     metric=\"eval_s_f1\",\n","    #     mode=\"max\",\n","    #     max_t=1,\n","    #     grace_period=1,\n","    #     reduction_factor=2)\n","\n","    reporter = CLIReporter(\n","        parameter_columns={\n","            \"weight_decay\": \"w_decay\",\n","            \"learning_rate\": \"lr\",\n","            \"dropout\": \"dropout\",\n","            \"alpha\": \"alpha\",\n","            \"per_device_train_batch_size\": \"train_bs/gpu\",\n","            \"num_train_epochs\": \"num_epochs\"\n","        },\n","        metric_columns=[\n","            \"eval_s_accuracy\", \"eval_loss\", \"eval_s_f1\", \"steps\", \"training_iteration\"\n","        ])\n","\n","    trainer.hyperparameter_search(\n","        hp_space=lambda _: tune_config_ASHA,\n","        backend=\"ray\",\n","        # compute_objective=my_objective,\n","        direction=\"maximize\",\n","        n_trials=num_samples,\n","        resources_per_trial={\n","            \"cpu\": 2,\n","            \"gpu\": gpus_per_trial\n","        },\n","        # scheduler=scheduler,\n","        keep_checkpoints_num=1,\n","        checkpoint_score_attr=\"training_iteration\",\n","        stop={\"training_iteration\": 1} if smoke_test else None,\n","        progress_reporter=reporter,\n","        local_dir=\"~/ray_results/\",\n","        name=\"tune_transformer\",\n","        loggers=DEFAULT_LOGGERS + (WandbLogger,))\n","        # time_budget_s=60*60*10) # 10 hours"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1mDMj5yw6-clJU7cRMMF-Q9-CwF_SV-GG"},"id":"R56EET-8kvC3","outputId":"0fdf4503-896e-4e14-8194-4804e3e57412"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["tune_transformer(num_samples=3, gpus_per_trial=1, smoke_test=False)\n","# tune_transformer(num_samples=1, gpus_per_trial=0, smoke_test=True)"]},{"cell_type":"markdown","metadata":{"id":"yngPQIlDdmKd"},"source":["standard hyperparameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUSOFFnGPDyp"},"outputs":[],"source":["# saves our models to artifacts in WandB\n","import wandb\n","%env WANDB_LOG_MODEL=true\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqc0rD6rVp2f"},"outputs":[],"source":["import os\n","import pickle\n","\n","import ray\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import PopulationBasedTraining\n","from transformers import AutoConfig, \\\n","    AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from ray.tune.logger import DEFAULT_LOGGERS\n","from ray.tune.integration.wandb import WandbLoggerCallback, WandbLogger\n","from transformers import ElectraTokenizerFast, ElectraForSequenceClassification, BertTokenizer, BertForSequenceClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa578LQbSUYj"},"outputs":[],"source":["model_name = 'bert-base-uncased'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1622766327716,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"F90QttEzFxT7","outputId":"7c9be69d-2322-4c7e-9fea-4291159f6e3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_PROJECT=BERT-base-uncased-HP-Tuning\n"]}],"source":["project_name = \"BERT-base-uncased-HP-Tuning\"\n","%env WANDB_PROJECT=BERT-base-uncased-HP-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsVonOvqTpZe"},"outputs":[],"source":["from datasets import DatasetDict\n","\n","with open(r\"/content/drive/MyDrive/Thesis/Datasets/book_preprocessing/PreTokenized/BERT_UNCASED_NER_512/train_dataset.pkl\", \"rb\") as input_file:\n","  train_dataset = pickle.load(input_file)\n","\n","with open(r\"/content/drive/MyDrive/Thesis/Datasets/book_preprocessing/PreTokenized/BERT_UNCASED_NER_512/val_dataset.pkl\", \"rb\") as input_file:\n","  val_dataset = pickle.load(input_file)\n","\n","with open(r\"/content/drive/MyDrive/Thesis/Datasets/book_preprocessing/PreTokenized/BERT_UNCASED_NER_512/test_dataset.pkl\", \"rb\") as input_file:\n","  test_dataset = pickle.load(input_file)\n","\n","chunked_encoded_dataset = DatasetDict({'train': train_dataset, 'validation': val_dataset, 'test': test_dataset})\n","chunked_encoded_dataset = chunked_encoded_dataset.rename_column('success_label', 'labels')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Za_8B6C9KOTM"},"outputs":[],"source":["def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","def tune_transformer(num_samples=8,\n","                     gpus_per_trial=0,\n","                     smoke_test=False,\n","                     ray_address=None):\n","    ray.init(ray_address, log_to_driver=True)\n","    data_dir_name = \"./data\" if not smoke_test else \"./test_data\"\n","    data_dir = os.path.abspath(os.path.join(os.getcwd(), data_dir_name))\n","    if not os.path.exists(data_dir):\n","        os.mkdir(data_dir, 0o755)\n","\n","    # Change these as needed.\n","    # model_name = 'google/electra-small-discriminator' if not smoke_test \\\n","    #     else 'google/electra-small-discriminator'\n","    task_name = \"grs\"\n","\n","    task_data_dir = os.path.join(data_dir, task_name.upper())\n","\n","    num_labels = 2\n","\n","    # config = AutoConfig.from_pretrained(\n","    #     model_name, num_labels=num_labels, finetuning_task=task_name)\n","\n","    # Download and cache tokenizer, model, and features\n","    print(\"Downloading and caching Tokenizer\")\n","    # tokenizer = ElectraTokenizerFast.from_pretrained('google/electra-small-discriminator', additional_special_tokens = ['[CHARACTER]'])\n","    tokenizer = BertTokenizer.from_pretrained(model_name, additional_special_tokens = ['[CHARACTER]'])\n","    \n","    # Triggers tokenizer download to cache\n","    # print(\"Downloading and caching pre-trained model\")\n","    # AutoModelForSequenceClassification.from_pretrained(\n","    #     model_name,\n","    #     config=config,\n","    # )\n","\n","    def get_model():\n","        # model = ElectraForSequenceClassification.from_pretrained('/content/drive/MyDrive/Thesis/Models/ELECTRA_small_pretrained', num_labels=2)\n","        model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","        model.resize_token_embeddings(len(tokenizer))\n","        return model\n","\n","    train_dataset = chunked_encoded_dataset['train']\n","    eval_dataset = chunked_encoded_dataset['validation']\n","\n","    training_args = TrainingArguments(\n","        project_name,\n","        # output_dir=\".\",\n","        learning_rate=1e-5,  # config\n","        do_train=True,\n","        do_eval=True,\n","        no_cuda=gpus_per_trial \u003c= 0,\n","        evaluation_strategy=\"epoch\",\n","        load_best_model_at_end=True,\n","        num_train_epochs=2,  # config\n","        max_steps=-1,\n","        per_device_train_batch_size=16,  # config\n","        per_device_eval_batch_size=16,  # config\n","        warmup_steps=0,\n","        weight_decay=0.1,  # config\n","        # logging_dir=\"./logs\",\n","    )\n","\n","    training_args._n_gpu = gpus_per_trial\n","\n","    trainer = Trainer(\n","        model_init=get_model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics)\n","\n","    tune_config = {\n","        # \"per_device_train_batch_size\": 16,\n","        \"per_device_eval_batch_size\": 32,\n","        \"num_train_epochs\": tune.choice([2, 3, 4, 5]),\n","        \"max_steps\": 1 if smoke_test else -1,  # Used for smoke test.\n","        \"wandb\": {\n","            \"project\": project_name,\n","            \"api_key\": config['WandB']['api_key'],\n","            \"log_config\": True\n","        }\n","    }\n","\n","    scheduler = PopulationBasedTraining(\n","        time_attr=\"training_iteration\",\n","        metric=\"eval_f1\",\n","        mode=\"max\",\n","        perturbation_interval=1,\n","        hyperparam_mutations={\n","            \"weight_decay\": tune.uniform(0.0, 0.3),\n","            \"warmup_steps\": tune.choice([0, 50, 100, 500, 1000]),\n","            \"learning_rate\": tune.uniform(1e-5, 4e-5),\n","            \"per_device_train_batch_size\": [8, 16],\n","        })\n","\n","    reporter = CLIReporter(\n","        parameter_columns={\n","            \"weight_decay\": \"w_decay\",\n","            \"learning_rate\": \"lr\",\n","            \"per_device_train_batch_size\": \"train_bs/gpu\",\n","            \"num_train_epochs\": \"num_epochs\"\n","        })\n","\n","    trainer.hyperparameter_search(\n","        hp_space=lambda _: tune_config,\n","        backend=\"ray\",\n","        n_trials=num_samples,\n","        resources_per_trial={\n","            \"cpu\": 1,\n","            \"gpu\": gpus_per_trial\n","        },\n","        scheduler=scheduler,\n","        keep_checkpoints_num=1,\n","        checkpoint_score_attr=\"training_iteration\",\n","        stop={\"training_iteration\": 1} if smoke_test else None,\n","        progress_reporter=reporter,\n","        local_dir=\"~/ray_results/\",\n","        name=\"tune_transformer_pbt\",\n","        # log_to_file=True,\n","        loggers=DEFAULT_LOGGERS + (WandbLogger, ),\n","        time_budget_s=60*15\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VD1-EmsGKY9l"},"outputs":[],"source":["import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\n","    \"--smoke-test\", action=\"store_true\", help=\"Finish quickly for testing\")\n","parser.add_argument(\n","    \"--ray-address\",\n","    type=str,\n","    default=None,\n","    help=\"Address to use for Ray. \"\n","    \"Use \\\"auto\\\" for cluster. \"\n","    \"Defaults to None for local.\")\n","args, _ = parser.parse_known_args()\n","\n","if args.smoke_test:\n","    tune_transformer(\n","        num_samples=1,\n","        gpus_per_trial=0,\n","        smoke_test=True,\n","        ray_address=args.ray_address)\n","else:\n","    # You can change the number of GPUs here:\n","    tune_transformer(\n","        num_samples=15, gpus_per_trial=1, ray_address=args.ray_address)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVQNsDDuLuG_"},"outputs":[],"source":["ray.shutdown()"]},{"cell_type":"markdown","metadata":{"id":"tI83z4OAhYpi"},"source":["# UNNEEDED CODE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qPERDTBVqA-"},"outputs":[],"source":["def tokenize_w_overlap(example, tokenizer, chunk_len = 512, overlap_len = 50):\n","    data_tokenize = tokenizer(example['text'], \n","                    max_length = chunk_len,\n","                    add_special_tokens=True,\n","                    return_attention_mask=True,\n","                    return_token_type_ids=True,\n","                    return_overflowing_tokens = True,\n","                    return_tensors = 'np')\n","\n","    long_terms_token = []\n","    input_ids_list = []\n","    attention_mask_list = []\n","    token_type_ids_list = []\n","    targets_list = []\n","\n","    previous_input_ids = data_tokenize[\"input_ids\"].reshape(-1)\n","    previous_attention_mask = data_tokenize[\"attention_mask\"].reshape(-1)\n","    previous_token_type_ids = data_tokenize[\"token_type_ids\"].reshape(-1)\n","    remain = data_tokenize[\"overflowing_tokens\"].reshape(-1)\n","    \n","    input_ids_list.append(previous_input_ids)\n","    attention_mask_list.append(previous_attention_mask)\n","    token_type_ids_list.append(previous_token_type_ids)\n","\n","    if remain is not None:\n","      idxs = range(len(remain)+chunk_len)\n","      idxs = idxs[(chunk_len-overlap_len-2)\n","                    ::(chunk_len-overlap_len-2)]\n","      input_ids_first_overlap = previous_input_ids[-(\n","          overlap_len+1):-1]\n","      start_token = np.array([101])\n","      end_token = np.array([102])\n","\n","      for i, idx in enumerate(idxs):\n","          if i == 0:\n","              input_ids = np.concatenate((input_ids_first_overlap, remain[:idx])) # building the 2nd chunk\n","          elif i == len(idxs):\n","              input_ids = remain[idx:]\n","          elif previous_idx \u003e= len(remain):\n","              break\n","          else:\n","              input_ids = remain[(previous_idx-overlap_len):idx]\n","\n","          previous_idx = idx\n","\n","          nb_token = len(input_ids)+2\n","          attention_mask = np.ones(chunk_len)\n","          attention_mask[nb_token:chunk_len] = 0 # only will take effect on the last chunk\n","          token_type_ids = np.zeros(chunk_len)\n","          input_ids = np.concatenate((start_token, input_ids, end_token))\n","\n","          if chunk_len-nb_token \u003e 0: # add padding, only can pass on last chunk\n","              padding = np.zeros(chunk_len-nb_token)\n","              input_ids = np.concatenate((input_ids, padding))\n","\n","          input_ids_list.append(input_ids)\n","          attention_mask_list.append(attention_mask)\n","          token_type_ids_list.append(token_type_ids)\n","\n","      print(input_ids_list)\n","\n","      return {\n","          'input_ids': input_ids_list,  # torch.tensor(ids, dtype=torch.long),\n","          'attention_mask': attention_mask_list,\n","          'token_type_ids': token_type_ids_list,\n","          'success_label': np.array([example['success_label']] * len(input_ids_list)),\n","          'genre': np.array([example['genre']] * len(input_ids_list))\n","          # 'len': [np.array(len(targets_list), dtype=torch.long)]\n","      }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cM0zn9NVqgf"},"outputs":[],"source":["# When batched = True, we take in multiple examples\n","def chunk_and_encode_examples_w_overlap(examples):\n","  mega_dict = {'attention_mask': [], 'genre': [], 'input_ids': [], 'success_label': [], 'token_type_ids': [], 'book_title': []}\n","  for i in range(len(examples['text'])):\n","    book_sample = {'text': examples['text'][i], 'genre': examples['genre'][i], 'success_label': examples['success_label'][i], 'book_title':examples['book_title'][i]}\n","    dictOfTokenizedChunks = tokenize_w_overlap(book_sample, tokenizer)\n","    for key, value in dictOfTokenizedChunks.items():\n","      mega_dict[key].extend(value)\n","  return mega_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7321,"status":"ok","timestamp":1624292292811,"user":{"displayName":"Luca Guarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSVZPJxC-6rJfC9ZK-bceU_7VuBnoBQg1qMN4Fng=s64","userId":"08879576481210952349"},"user_tz":420},"id":"qL8HlV6LXRtu","outputId":"e77e119e-011e-4302-df66-2fc249b587f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-06-21 16:18:05.542348: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/transformers/commands/env.py:50: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","2021-06-21 16:18:07.217176: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n","2021-06-21 16:18:07.218520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-21 16:18:07.219176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2021-06-21 16:18:07.219234: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-06-21 16:18:07.332753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n","2021-06-21 16:18:07.332862: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n","2021-06-21 16:18:07.445759: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n","2021-06-21 16:18:07.461836: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n","2021-06-21 16:18:07.639584: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n","2021-06-21 16:18:07.682974: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n","2021-06-21 16:18:07.687243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n","2021-06-21 16:18:07.687387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-21 16:18:07.688022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-21 16:18:07.691182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n","2021-06-21 16:18:07.694473: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-06-21 16:18:10.081511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-06-21 16:18:10.081560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n","2021-06-21 16:18:10.081569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n","2021-06-21 16:18:10.081735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-21 16:18:10.082359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-21 16:18:10.082931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-06-21 16:18:10.083439: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-06-21 16:18:10.083480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 15433 MB memory) -\u003e physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","\n","Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n","\n","- `transformers` version: 4.7.0\n","- Platform: Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic\n","- Python version: 3.7.10\n","- PyTorch version (GPU?): 1.9.0+cu102 (True)\n","- Tensorflow version (GPU?): 2.5.0 (True)\n","- Using GPU in script?: \u003cfill in\u003e\n","- Using distributed or parallel set-up in script?: \u003cfill in\u003e\n","\n"]}],"source":["!transformers-cli env"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AN57wiBZXVrl"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMzqO199KPYzw8ZirxuMLU/","collapsed_sections":["UlNbZBmyt_FS","xNtzoZdGJKF7","tI83z4OAhYpi"],"mount_file_id":"17P7vkejHtBSgHb_vbRCYK_xTCVffMWId","name":"Goodreads_stage1.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"027a63e59fd846a0a8b2802d55180cda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07157936e1f148d8b8e92a1bcc76d9c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0778f5bcc2fc47589d298b49e41b030b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12e374c6985147f6b0b6473280b48365":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"140cde2565c849bda260095566527cf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c8395af31bd499087b2c6033450e812","IPY_MODEL_e7177914dfbe4f85b762400e567ee591","IPY_MODEL_2d93b9cd777d4f23a203b796bb9ad272"],"layout":"IPY_MODEL_12e374c6985147f6b0b6473280b48365"}},"1854a52e3b6f4a45aa0201076e10facc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1905657399f74d6a888be426ad7a7f3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_89372af01ef84c08bdc78d5af43f6d1b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_59fc0dc9b49444a79b26d2a88b975f3d","value":1}},"25c301791e5648d6a191037be2ad7900":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9ec0a7822e47b992e44d4b4eabc9ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bd099f1453a482689fc32eb82e51348":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d93b9cd777d4f23a203b796bb9ad272":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25c301791e5648d6a191037be2ad7900","placeholder":"​","style":"IPY_MODEL_70c1214cd1b948a1b783505c427b2a73","value":" 139/0 [01:11\u0026lt;00:00,  1.95 examples/s]"}},"3013b3d1302e418a899759476164edff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30b2f319d0c04552be59fc4d34947acf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af4168de21e4414fba598f4b7d9f133b","max":558582766,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76e27e860fd14b148ad74a71edb344ff","value":558582766}},"321991cacd3c4e928dbc9dba2ff9d648":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4e5890bd371422da51290791f02a97a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec013794c4814830bf3f99a17b20983f","value":1}},"331d24cae3484c138e6363bebd57fd25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33cf7775055c4479883ffb8df436106b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ab51436e988434cba4cc7251a7173b8","placeholder":"​","style":"IPY_MODEL_7ffc7e96c33b4e78be64747d95a9ed74","value":""}},"3a02dc4825b046b2bee3d89a94282f37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c0cc693a8a646059c77adb580ee3b49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b56e5b50f5424185eaf416d012ecf4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f0878593164d49a10f521cec3ef0c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f654c8e8066468281b517f15162aa03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f489c49a50f64dd8a439f33e2a3a3d93","placeholder":"​","style":"IPY_MODEL_027a63e59fd846a0a8b2802d55180cda","value":" 1/1 [00:08\u0026lt;00:00,  8.91s/ba]"}},"5301a68e13b5447ab69ef46fc1d7655b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5693ae6abe024acdbb40f8d75b2280b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57335874541f490c8e74399efce2f070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_707bb99700984c8e909f5842865d1fbb","IPY_MODEL_30b2f319d0c04552be59fc4d34947acf","IPY_MODEL_82bc7efb7e8748ceb77372c21d7c3155"],"layout":"IPY_MODEL_07157936e1f148d8b8e92a1bcc76d9c7"}},"589e408bc8b54165a150c0b5c1afdec8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59fc0dc9b49444a79b26d2a88b975f3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ae51d7cfb234d2290f5f0cbf4c1d838":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6265ba8b14eb4d77979475f27b20ed49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7629622ffa7a46da98a8469a56799183","IPY_MODEL_855e716a3f444f669e719b6893d45c71","IPY_MODEL_6acfe443eaf14c75ab28f2863d2a2e5e"],"layout":"IPY_MODEL_0778f5bcc2fc47589d298b49e41b030b"}},"64b2150d960d4bfc81f5021602ee8fb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33cf7775055c4479883ffb8df436106b","IPY_MODEL_1905657399f74d6a888be426ad7a7f3e","IPY_MODEL_ebacd6f31f9d49d3b533cdc231a70e52"],"layout":"IPY_MODEL_a147febcd6a94de3ba265d82ce9e2a71"}},"66af5a8512bd451fa9af725f57dc1caa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79f2f5dcc1eb474588fe116c8e3e8a9d","IPY_MODEL_ac53d9391e434220a6d0b5f865baddd5","IPY_MODEL_4f654c8e8066468281b517f15162aa03"],"layout":"IPY_MODEL_98338dd699ae43a78e661884cc1f1d81"}},"6ab51436e988434cba4cc7251a7173b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6acfe443eaf14c75ab28f2863d2a2e5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd099f1453a482689fc32eb82e51348","placeholder":"​","style":"IPY_MODEL_ea1ad33c30f34cb78a43740a37e3ca6b","value":" 1/1 [00:18\u0026lt;00:00, 18.06s/ba]"}},"6e91ab83b7864686b4a02117992744ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad50fbba6e174b6d88a97f9b7b1fb2ed","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6aafd27fd344f4a86802bec850672ad","value":1}},"707bb99700984c8e909f5842865d1fbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_331d24cae3484c138e6363bebd57fd25","placeholder":"​","style":"IPY_MODEL_5693ae6abe024acdbb40f8d75b2280b5","value":"Downloading: 100%"}},"70c1214cd1b948a1b783505c427b2a73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7629622ffa7a46da98a8469a56799183":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45b56e5b50f5424185eaf416d012ecf4","placeholder":"​","style":"IPY_MODEL_3013b3d1302e418a899759476164edff","value":"100%"}},"76e27e860fd14b148ad74a71edb344ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79f2f5dcc1eb474588fe116c8e3e8a9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a02dc4825b046b2bee3d89a94282f37","placeholder":"​","style":"IPY_MODEL_8e4609154c7c481d99d646edf40ca638","value":"100%"}},"7ffc7e96c33b4e78be64747d95a9ed74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82bc7efb7e8748ceb77372c21d7c3155":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c0cc693a8a646059c77adb580ee3b49","placeholder":"​","style":"IPY_MODEL_dd65014411024bae8f0b9eb8dec011a5","value":" 559M/559M [00:47\u0026lt;00:00, 12.5MB/s]"}},"855e716a3f444f669e719b6893d45c71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46f0878593164d49a10f521cec3ef0c0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b01cecf30f1d4f12b2d8ccef40f8ade8","value":1}},"86dfc87b5ff54598bbab58f752e22712":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89372af01ef84c08bdc78d5af43f6d1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8e4609154c7c481d99d646edf40ca638":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"913a1f91572b4fc7b7be03c7c20de462":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98338dd699ae43a78e661884cc1f1d81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"985ff7755f8a4af19f7cfedd814e212b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ae51d7cfb234d2290f5f0cbf4c1d838","placeholder":"​","style":"IPY_MODEL_c4a24de5e225492995f6c5c1f6a546ac","value":"100%"}},"9c8395af31bd499087b2c6033450e812":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b9ec0a7822e47b992e44d4b4eabc9ee","placeholder":"​","style":"IPY_MODEL_9df1f0f2f48b49558155e21dcb56d375","value":""}},"9df1f0f2f48b49558155e21dcb56d375":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e0177235a7446b2a13d4fc289d08f59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8f6657347ff42acbd32c7636933d4a2","IPY_MODEL_6e91ab83b7864686b4a02117992744ee","IPY_MODEL_a9c2ce4e9c65405daa654523d4687199"],"layout":"IPY_MODEL_a8acf4f12b9749408fe4487495930101"}},"a147febcd6a94de3ba265d82ce9e2a71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8acf4f12b9749408fe4487495930101":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9c2ce4e9c65405daa654523d4687199":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2a641a551eb4efe9cfddaecef47b5bc","placeholder":"​","style":"IPY_MODEL_86dfc87b5ff54598bbab58f752e22712","value":" 555/0 [04:02\u0026lt;00:00,  1.92 examples/s]"}},"ac53d9391e434220a6d0b5f865baddd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4fb8cf2ae3c4971ae00ffb3b3366554","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_913a1f91572b4fc7b7be03c7c20de462","value":1}},"ac6af21188bf423f850eadf5b109dec9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_985ff7755f8a4af19f7cfedd814e212b","IPY_MODEL_321991cacd3c4e928dbc9dba2ff9d648","IPY_MODEL_bb60ed110bc74a3aa48573fa1e30b7ca"],"layout":"IPY_MODEL_ef7de885a55f40b09a7fc44a5df1b767"}},"ad50fbba6e174b6d88a97f9b7b1fb2ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"af4168de21e4414fba598f4b7d9f133b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b01cecf30f1d4f12b2d8ccef40f8ade8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b54a5073118a4805a8dba59e56203b0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bb60ed110bc74a3aa48573fa1e30b7ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eef0922a3ca04acfbe2879117fd0f61b","placeholder":"​","style":"IPY_MODEL_df4feb028a904a0e8ac77641a0ae7b43","value":" 1/1 [00:36\u0026lt;00:00, 36.38s/ba]"}},"c4a24de5e225492995f6c5c1f6a546ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4e5890bd371422da51290791f02a97a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c68b20b4f1514333a1314e7e0fd56998":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8f6657347ff42acbd32c7636933d4a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1854a52e3b6f4a45aa0201076e10facc","placeholder":"​","style":"IPY_MODEL_589e408bc8b54165a150c0b5c1afdec8","value":""}},"d4fb8cf2ae3c4971ae00ffb3b3366554":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da4d6fdb9f534a77afa0175ecf79791b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd65014411024bae8f0b9eb8dec011a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df4feb028a904a0e8ac77641a0ae7b43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2a641a551eb4efe9cfddaecef47b5bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7177914dfbe4f85b762400e567ee591":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_b54a5073118a4805a8dba59e56203b0f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5301a68e13b5447ab69ef46fc1d7655b","value":1}},"ea1ad33c30f34cb78a43740a37e3ca6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebacd6f31f9d49d3b533cdc231a70e52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c68b20b4f1514333a1314e7e0fd56998","placeholder":"​","style":"IPY_MODEL_da4d6fdb9f534a77afa0175ecf79791b","value":" 290/0 [02:27\u0026lt;00:00,  1.95 examples/s]"}},"ec013794c4814830bf3f99a17b20983f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eef0922a3ca04acfbe2879117fd0f61b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef7de885a55f40b09a7fc44a5df1b767":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f489c49a50f64dd8a439f33e2a3a3d93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6aafd27fd344f4a86802bec850672ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}